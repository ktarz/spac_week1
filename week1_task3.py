#Importing csv library
import csv

# Creating function to clean the csvfile for whitespacelines generated by extra commas in the rows.
# Also adding empty rows if a row is not long enough to hit the amount of headers in the data.
# The function takes to files as input, one which is the actual data and another which is the data to be generated for future use.

def clean_csv(inputfile, outputfile):
    with open(inputfile, newline='', encoding='utf-8') as filein, \
         open(outputfile, "w", newline='', encoding='utf-8') as fileout:
             reader = csv.reader(filein)
             writer = csv.writer(fileout)

             header = next(reader)
             numberofcolumns = len(header)
             writer.writerow(header)

             for row in reader:
                 if len(row) == numberofcolumns + 1:
                     if "" in row:
                         row.remove("")
                         print("case1")
                 elif len(row) < numberofcolumns:
                     row += [""] * (numberofcolumns - len(row))
                     print("case2")
                 elif len(row) > numberofcolumns:
                     row = row[:numberofcolumns]
                     print("case3")
                 writer.writerow(row)

# Running cleaning function in this section
clean_csv("source_data.csv", "cleanrows.csv")

# Opening the cleaned file and removing completely empty rows

with open("cleanrows.csv", encoding="utf-8") as filein, \
     open("whitespacesremoved.csv", "w", encoding="utf-8") as fileout:
         for line in filein:
             if line.strip(", \n") == "":
                 continue
             fileout.write(line)

# Creating 2 functions to validate certain data
# is_int validates if the val input is integer
# is_float validates if the val input is float

def is_int(val):
    try:
        int(val)
        return True
    except (ValueError, TypeError):
        return False

def is_float(val):
    try:
        float(val)
        return True
    except (ValueError, TypeError):
        return False

# Function to validate the data in a line
# Uses the is_int and is_float functions to validate numeric values
# Simple if statement to validate if something in the email column is an email - must include @ and .com
# As removing invalid rows is a bad idea I decided to create a new csv file that only includes the bad rows -
# and their row index in the original file so that a human user can inspect every error.

def validate(inputcsv,outputcsv, errorfile):
    with open(inputcsv, newline="", encoding="utf-8") as filein, \
         open(outputcsv, "w", newline="", encoding="utf-8") as fileout, \
         open(errorfile, "w", newline="", encoding="utf-8") as errorfile:
             reader = csv.DictReader(filein)
             fieldnames = reader.fieldnames

             data_writer = csv.DictWriter(fileout, fieldnames=fieldnames)
             error_writer = csv.DictWriter(errorfile, fieldnames=["row_number"] + fieldnames + ["error_notes"])

             data_writer.writeheader()
             error_writer.writeheader()

             for i, row in enumerate(reader, start=2):
                 row = {k: (v.strip() if v is not None else "") for k, v in row.items()}
                 errors = []

                 if row["customer_id"] and not is_int(row["customer_id"]):
                     errors.append("Invalid customerID")
                 if row["email"] and "@" not in row["email"]:
                     errors.append("Invalid email")
                 if row["email"] and ".com" not in row["email"]:
                     errors.append("Invalid email")
                 if row["purchase_amount"] and not is_float(row["purchase_amount"]):
                     errors.append("Invalid purchaseprice")

                 data_writer.writerow(row)

                 if errors:
                     error_row = {"row_number": i, **row, "error_notes": ";".join(errors)}
                     error_writer.writerow(error_row)

# Runs the validate function to create a final.csv and a error_flags.csv file
validate("whitespacesremoved.csv","final.csv","error_flags.csv")
